# Intelligent Offline Voice Control Transcription System

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![Windows](https://img.shields.io/badge/platform-Windows%2010%2F11-lightgrey.svg)](https://www.microsoft.com/windows)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

## Overview

An **enterprise-grade, fully offline voice control transcription system** for Windows, designed specifically for industrial automation and robotic control applications. The system leverages OpenAI Whisper deep learning models with optimized inference, natural language command disambiguation, and Windows SAPI TTS integration to deliver real-time voice command recognition with high accuracy and reliability.

**Key Value Propositions:**
- ‚úÖ **100% Offline Operation** - Complete privacy, no cloud dependencies
- ‚úÖ **Industrial-Grade Reliability** - Multi-threaded architecture with comprehensive error handling
- ‚úÖ **Wake Word Activation** - "susie" wake word for hands-free operation
- ‚úÖ **Intelligent Command Matching** - 5-stage disambiguation algorithm with fuzzy search
- ‚úÖ **Production Ready** - Single-file executable deployment (<300MB)
- ‚úÖ **Real-Time Feedback** - Windows SAPI TTS with asynchronous processing
- ‚úÖ **Enterprise Architecture** - Modular design with 5 core components

---

## System Architecture

### Core Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    VoiceControlApp (GUI)                        ‚îÇ
‚îÇ              Tkinter-based UI with health monitoring            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚ñ∫ AudioEngine (audio_engine_v2.py)
         ‚îÇ    ‚Ä¢ Real-time audio capture (PyAudio)
         ‚îÇ    ‚Ä¢ Whisper-based transcription with VAD
         ‚îÇ    ‚Ä¢ Wake word detection
         ‚îÇ    ‚Ä¢ Hallucination filtering & deduplication
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚ñ∫ ModelManager (model_manager.py)
         ‚îÇ    ‚Ä¢ Whisper model lifecycle management
         ‚îÇ    ‚Ä¢ Offline deployment support
         ‚îÇ    ‚Ä¢ Asynchronous loading
         ‚îÇ    ‚Ä¢ HuggingFace cache integration
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚ñ∫ CommandManager (command_manager.py)
         ‚îÇ    ‚Ä¢ 5-stage command disambiguation
         ‚îÇ    ‚Ä¢ Dynamic weight optimization
         ‚îÇ    ‚Ä¢ JSON-based persistence
         ‚îÇ    ‚Ä¢ Usage analytics
         ‚îÇ
         ‚îî‚îÄ‚îÄ‚ñ∫ TTSEngine (tts_engine_v2.py)
              ‚Ä¢ Windows SAPI integration (win32com)
              ‚Ä¢ Asynchronous queue processing
              ‚Ä¢ Priority-based task scheduling
              ‚Ä¢ COM lifecycle management
```

### Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Speech Recognition** | OpenAI Whisper (faster-whisper) | STT engine with CTranslate2 optimization |
| **Audio Processing** | PyAudio + NumPy | Real-time audio capture and preprocessing |
| **Voice Activity Detection** | ONNX Runtime + Silero VAD | Speech segment detection |
| **Text-to-Speech** | Windows SAPI (win32com) | Native OS-level TTS |
| **NLP** | SequenceMatcher + Custom | Command disambiguation and fuzzy matching |
| **GUI** | Tkinter | Cross-platform UI framework |
| **Packaging** | PyInstaller | Single-file executable generation |

---

## Features

### Speech Recognition
- üé§ **Real-time Transcription** - 500-800ms latency for 2-3 second audio
- üîä **VAD Filtering** - Automatic noise suppression and speech detection
- üéØ **High Accuracy** - >90% command recognition for trained phrases
- üåê **Multi-Model Support** - tiny (39MB) ‚Üí large (1.55GB)
- üîí **Fully Offline** - No cloud dependencies or data transmission

### Command Processing
- üß† **Intelligent Matching** - 5-stage disambiguation algorithm
  1. Exact match checking
  2. Contextual lookahead (prevents truncation)
  3. Substring word-level matching
  4. Prefix-based similarity scoring
  5. Fuzzy matching with penalties
- üìä **Dynamic Weighting** - Usage-based priority adjustment (1.0-3.0)
- üéØ **Hotword Boosting** - Enhanced recognition for high-priority commands
- üìà **Usage Analytics** - Track frequency, success rate, timestamps

### User Interface
- üñ•Ô∏è **Modern GUI** - 4-tab interface (Listen, Commands, Training, System)
- üìä **Real-Time Status** - Live system health monitoring
- ‚öôÔ∏è **Configuration Management** - Visual command/TTS settings editor
- üìù **Activity Logging** - Timestamped command history
- üîÑ **Hot Reload** - Update configs without restart (dev mode)

### System Integration
- üîó **File-Based API** - Writes commands to `output.txt` for external systems
- üéôÔ∏è **Audio Feedback** - TTS confirmation for all recognized commands
- üîß **Configurable** - JSON-based settings for commands and TTS
- üì¶ **Portable** - Single EXE deployment with external configs

---

## Quick Start

### System Requirements

**Minimum:**
- Windows 10/11 (64-bit)
- Intel i5 / AMD Ryzen 5 (or equivalent)
- 4GB RAM
- 500MB disk space
- Microphone input device
- Internet (first-time model download only)

**Recommended:**
- 8GB RAM
- 1GB disk space (for larger models)
- Quiet recording environment

### Installation

#### 1. Clone Repository
```powershell
git clone https://github.com/YounGuru03/voice-control-for-a-robot-system.git
cd voice-control-for-a-robot-system
```

#### 2. Install Dependencies
```powershell
# Install all required packages
pip install -r requirements.txt

# CRITICAL: Run pywin32 post-install (as Administrator)
python Scripts\pywin32_postinstall.py -install
```

#### 3. Verify Installation
```powershell
# Test critical imports
python -c "import faster_whisper, pyaudio, win32com.client; print('‚úì All dependencies OK')"
```

### Running the Application

#### Development Mode
```powershell
python main_voice_app.py
```

#### First Run Behavior
1. **Model Loading** (5-15 seconds)
   - Downloads Whisper base model (~74MB) to cache
   - Or uses local models from `local_models/` directory
2. **System Initialization** (3-5 seconds)
   - Initializes audio engine
   - Enumerates Windows SAPI voices
   - Loads command database
3. **Ready State**
   - GUI displays "Ready" status
   - TTS announces "Ready"
   - System enters standby mode

### Basic Usage Workflow

1. **Start Listening**
   - Click "Start Listening" button
   - System begins monitoring for wake word

2. **Activate with Wake Word**
   - Say "**susie**" clearly
   - System responds: "Speak now"
   - LED indicator shows active state

3. **Speak Command**
   - Say command (e.g., "open browser", "close window")
   - System transcribes and matches command
   - TTS confirms recognized command

4. **Command Output**
   - Recognized command written to `output.txt`
   - External systems can read this file for automation
   - System returns to standby mode

5. **Stop Listening**
   - Click "Stop Listening" to deactivate
   - System announces "Stopped"

---

## Configuration

### TTS Settings (`tts_config.json`)

Controls Windows SAPI text-to-speech behavior:

```json
{
  "voice_index": 0,           // Windows voice index (0-based)
  "rate": 0,                  // Speech rate: -10 (slowest) to 10 (fastest)
  "volume": 100,              // Volume: 0 (mute) to 100 (max)
  "enabled": true,            // Enable/disable TTS globally
  "queue_timeout": 0.5,       // Queue processing timeout (seconds)
  "max_text_length": 300,     // Max characters per TTS message
  "unicode_support": true     // Enable Unicode text preprocessing
}
```

**Location:** Created next to EXE on first run, editable by users.

### Command Database (`commands_hotwords.json`)

Defines recognizable commands with weight-based prioritization:

```json
{
  "commands": {
    "open browser": {
      "weight": 1.5,          // Recognition priority (1.0-3.0)
      "usage_count": 12,      // Times successfully recognized
      "last_used": "2025-11-11T20:30:15"
    },
    "close window": {
      "weight": 1.3,
      "usage_count": 5,
      "last_used": "2025-11-11T19:45:00"
    }
  },
  "settings": {
    "max_weight": 3.0,        // Maximum weight cap
    "weight_decay": 0.98      // Weekly decay for unused commands
  }
}
```

**Location:** Created next to EXE on first run. Hot-reloadable in dev mode.

**Weight System:**
- **1.0-1.5**: Normal priority
- **1.5-2.5**: High priority (frequently used)
- **2.5-3.0**: Critical priority (safety commands)

Weights auto-adjust based on:
- Successful recognition ‚Üí +0.1 weight
- Usage frequency tracking
- Time-based decay for inactive commands

---

## Command Management

### Adding Commands

#### Via GUI (Recommended)
1. Navigate to **Commands** tab
2. Enter command text in input field
3. Click **Add Command** button
4. Command appears in list with default weight (1.0)

#### Via JSON File
1. Edit `commands_hotwords.json` manually
2. Add command entry with metadata
3. Click **Reload JSON** in GUI (dev mode only)

**Example:**
```json
"open camera 1": {
  "weight": 1.2,
  "usage_count": 0,
  "last_used": null,
  "created": "2025-11-11T10:00:00"
}
```

### Training Commands

Improve recognition accuracy through repetition:

1. Go to **Training** tab
2. Select command from list
3. Click **Train Selected**
4. Speak command 3-5 times
5. Weight increases with each successful recognition
6. Monitor usage count and weight in real-time

**Training Benefits:**
- Increases weight ‚Üí higher recognition priority
- Records voice characteristics for your pronunciation
- Improves disambiguation against similar commands

### Managing Commands

**Delete:**
- Select command in **Commands** tab
- Click **Delete Selected**
- Confirms and removes from database

**Statistics:**
- View usage count, weight, last used timestamp
- Most used commands shown in **Training** tab
- Export stats via System tab ‚Üí Save Log

### Command Matching Algorithm

The system uses a 5-stage matching process:

```python
# Stage 1: Exact Match
if transcription == command:
    return command

# Stage 2: Contextual Lookahead (prevents truncation)
# e.g., "open robot cell" matches before "open robot"
if longer_command.startswith(transcription):
    return longer_command

# Stage 3: Substring Word-Level
# For numbered commands: "camera 1", "template 8"
if all(word in transcription for word in command.split()):
    return command

# Stage 4: Prefix-Based Disambiguation
# Group commands by common prefix (e.g., "open camera...")
# Select best match within group

# Stage 5: Fuzzy Matching
# SequenceMatcher ratio with weight bonus
# Penalty for missing words
similarity_score = match_ratio + weight_bonus - missing_word_penalty
```

**Special Cases:**
- "open one" vs "open main" ‚Üí Disambiguated via exact match
- "open robot cell" vs "open robot" ‚Üí Prefers longer match
- "template A" vs "template 8" ‚Üí Character-level matching

---

## Building for Production

### Enhanced Build System (v2.3.0)

The project includes a comprehensive build script with automatic dependency discovery and packaging optimization.

#### Build Command
```powershell
# From project root: d:\Projects\NTU
python .\build.py
```

#### Build Process

1. **Dependency Verification**
   - Checks all required packages (faster-whisper, pywin32, PyAudio, etc.)
   - Tests Windows SAPI voice enumeration
   - Validates ONNX Runtime for VAD support

2. **Runtime Hooks Generation**
   - `hook_com_init.py` - COM initialization for SAPI TTS
   - `hook_env_setup.py` - Path resolution and environment setup

3. **Binary Discovery**
   - Auto-detects PortAudio DLLs (PyAudio backend)
   - Includes CTranslate2 native libraries
   - Bundles ONNX Runtime for VAD
   - **CRITICAL:** Includes `faster_whisper/assets/silero_vad_v6.onnx`

4. **Spec File Generation**
   - 157 hidden imports (COM, faster-whisper, tokenizers, numpy)
   - Data files (configs, VAD model, local models)
   - Excludes large unused packages (torch, tensorflow, matplotlib)

5. **PyInstaller Execution**
   - Single-file onefile build
   - Windowed mode (no console)
   - UPX compression disabled (prevents DLL corruption)
   - Strip disabled (avoids tool missing errors)

#### Build Output

```
dist/
  ‚îú‚îÄ‚îÄ VoiceControl.exe           # Single executable (~250-300MB)
  ‚îî‚îÄ‚îÄ verification_report.txt    # Build summary

build_log_<timestamp>.txt         # Detailed build log
```

#### Build Configuration

Edit `BUILD_CONFIG` in `build.py` to customize:

```python
BUILD_CONFIG = {
    "app_name": "VoiceControl",
    "windowed": True,              # False = show console (debugging)
    "require_admin": False,        # True = request UAC elevation
    "include_local_models": True,  # Bundle local_models/ directory
    "include_onnxruntime": True,   # Include ONNX for VAD (disable to reduce size)
    "discover_binaries": True      # Auto-find DLLs
}
```

#### Size Optimization

**Reduce executable size:**
```python
"include_onnxruntime": False,   # Saves ~50-80MB (disables VAD)
"include_local_models": False   # Saves ~70-150MB (relies on download)
```

**Trade-offs:**
- Without ONNX: No VAD filtering, may recognize background noise
- Without local models: First run downloads model (~74MB for base)

### Deployment Package

#### Minimal Deployment (Online Mode)
```
VoiceControl.exe              # Single file
```
First run downloads model to: `%APPDATA%\voice_control_cache`

#### Offline Deployment (Recommended)
```
VoiceControl.exe
local_models/                 # Pre-downloaded models
  models--Systran--faster-whisper-base/
    refs/main
    snapshots/<hash>/
      config.json
      tokenizer.json
      vocabulary.txt
      model.bin
```

#### First Run Behavior
1. Extracts to temp: `C:\Users\<user>\AppData\Local\Temp\_MEI<random>`
2. Runtime hook copies configs next to EXE:
   - `commands_hotwords.json`
   - `tts_config.json`
   - `NTU.PNG`
3. If `local_models/` exists ‚Üí offline mode
4. Otherwise ‚Üí downloads to `%APPDATA%\voice_control_cache`

### Post-Build Verification

```powershell
# Run verification script
python .\verify_build.py
```

**Checks:**
- ‚úÖ Executable exists and size is appropriate
- ‚úÖ Config files present
- ‚úÖ VAD model source file found
- ‚úÖ Runtime hooks generated
- ‚úÖ Spec file includes VAD assets

### Distribution Checklist

- [ ] Build completed without errors
- [ ] Verification script passes all checks
- [ ] Test EXE launches GUI
- [ ] Windows SAPI voices enumerated
- [ ] "Ready" status appears after model load
- [ ] Wake word detection works
- [ ] Command recognition functional
- [ ] `stt_debug.log` shows no VAD errors

---

## Troubleshooting

### Common Issues

#### 1. VAD Model Missing
**Symptom:** `[ONNXRuntimeError] NO_SUCHFILE: silero_vad_v6.onnx`

**Solution:**
```powershell
# Rebuild with updated build.py (v2.3.0+)
python .\build.py
```

The build script now automatically includes `faster_whisper/assets/` directory.

#### 2. COM Initialization Error
**Symptom:** TTS fails with "COM not initialized" error

**Solution:**
```powershell
# Re-run pywin32 post-install as Administrator
python Scripts\pywin32_postinstall.py -install
```

Verify COM hook is included:
```powershell
# Check runtime_hooks/hook_com_init.py exists
dir runtime_hooks\
```

#### 3. Model Loading Timeout
**Symptom:** "Model loading failed or timeout" after 30 seconds

**Solutions:**
- **Online mode:** Check internet connection
- **Offline mode:** Ensure `local_models/` is next to EXE
- **Verify cache:** Check `%APPDATA%\voice_control_cache` is writable

#### 4. Audio Device Not Found
**Symptom:** PyAudio error on startup

**Solutions:**
- Check microphone in Windows Settings ‚Üí Sound ‚Üí Input
- Grant microphone permissions to application
- Try enabling admin mode: `require_admin=True` in `build.py`

#### 5. Poor Recognition Accuracy
**Symptom:** Commands frequently misrecognized or not detected

**Solutions:**
- **Check RMS levels:** `stt_debug.log` should show RMS > 0.01
- **Reduce noise:** Minimize background sound
- **Train commands:** Use Training tab for frequently-used phrases
- **Upgrade model:** Switch to "small" or "medium" model
- **Adjust microphone:** Increase input volume in Windows settings

#### 6. High CPU Usage
**Symptom:** CPU at 80-100% during recognition

**Solutions:**
- Use smaller model (tiny/base instead of medium/large)
- Ensure int8 quantization is enabled (default in faster-whisper)
- Check environment variables set by `hook_env_setup.py`:
  ```
  OMP_NUM_THREADS=1
  OMP_WAIT_POLICY=PASSIVE
  ```

#### 7. EXE Too Large
**Symptom:** VoiceControl.exe > 400MB

**Solutions:**
```python
# In build.py BUILD_CONFIG:
"include_onnxruntime": False,   # Disable VAD (~50-80MB savings)
"include_local_models": False   # Don't bundle models (~70-150MB savings)
```

Rebuild: `python .\build.py`

### Debug Logs

**stt_debug.log** - Created next to EXE when running
```
[2025-11-11 20:53:45] AudioEngine initialized
[2025-11-11 20:53:50] Recorded 46 frames; RMS=0.037072
[2025-11-11 20:53:50] VAD model found at C:\...\silero_vad_v6.onnx
[2025-11-11 20:53:51] Transcription result: 'susie'
[2025-11-11 20:53:51] Wake word detected
```

**Key log patterns:**
- `AudioEngine initialized` ‚Üí System started
- `VAD model found` ‚Üí VAD working correctly
- `RMS=<value>` ‚Üí Audio input level (should be >0.01 for speech)
- `Transcription result: '<text>'` ‚Üí Recognized text
- `Command matched: '<text>' -> '<command>'` ‚Üí Successful match

---

## Advanced Topics

### Model Selection Guide

| Model | Size | Speed | Accuracy | Use Case |
|-------|------|-------|----------|----------|
| **tiny** | 39MB | Fastest | Basic | Testing, low-power devices |
| **base** | 74MB | Fast | Good | **Default - Recommended balance** |
| **small** | 244MB | Medium | High | Production with better accuracy |
| **medium** | 769MB | Slow | Very High | High-stakes applications |
| **large** | 1.55GB | Slowest | Best | Maximum accuracy required |

**Switching models:**
1. Download model to `local_models/` or let system auto-download
2. Select model in **System** tab dropdown
3. System hot-swaps model without restart

### Performance Tuning

**Low Latency Configuration:**
```python
# In audio_engine_v2.py
self.chunk = 512              # Smaller chunks (default: 1024)
duration = 2.0                # Shorter recording (default: 3.0)
```

**High Accuracy Configuration:**
```python
# In audio_engine_v2.py
beam_size = 5                 # Larger beam search (default: 2)
self.min_similarity = 0.7     # Higher threshold (default: 0.6)
```

### Integration with External Systems

The system writes recognized commands to `output.txt` for consumption by other applications:

**Example integration (Python):**
```python
import time
from pathlib import Path

def monitor_commands():
    output_file = Path("output.txt")
    last_mtime = 0
    
    while True:
        if output_file.exists():
            mtime = output_file.stat().st_mtime
            if mtime > last_mtime:
                with open(output_file, 'r', encoding='utf-8') as f:
                    command = f.read().strip()
                execute_command(command)
                last_mtime = mtime
        time.sleep(0.1)

def execute_command(command: str):
    # Your robotic control logic here
    print(f"Executing: {command}")
```

**Example integration (C#/.NET):**
```csharp
using System;
using System.IO;
using System.Threading;

class CommandMonitor {
    static void Main() {
        var watcher = new FileSystemWatcher(".");
        watcher.Filter = "output.txt";
        watcher.Changed += OnCommandChanged;
        watcher.EnableRaisingEvents = true;
        
        Console.ReadLine();
    }
    
    static void OnCommandChanged(object sender, FileSystemEventArgs e) {
        var command = File.ReadAllText("output.txt").Trim();
        ExecuteCommand(command);
    }
    
    static void ExecuteCommand(string command) {
        Console.WriteLine($"Executing: {command}");
        // Your robotic control logic here
    }
}
```

### Custom Wake Words

To change the wake word from "susie" to your custom word:

```python
# In audio_engine_v2.py, locate detect_wake_word method:
def detect_wake_word(self, audio_data: np.ndarray, wake_word: str = "your_word") -> bool:
    # ... rest of implementation
```

**Best practices for custom wake words:**
- Choose 2-3 syllable words for best detection
- Avoid common words that might trigger accidentally
- Test thoroughly to adjust sensitivity if needed
- Consider phonetic clarity in your environment

---

## Performance Characteristics

### Latency Benchmarks

| Operation | Latency | Notes |
|-----------|---------|-------|
| Wake word detection | 200-300ms | From speech end to detection |
| Command transcription | 500-800ms | For 2-3 second audio |
| TTS feedback | 100-200ms | Queue processing time |
| Total interaction | <2 seconds | Wake word ‚Üí command output |

### Resource Usage

| Metric | Value | Configuration |
|--------|-------|---------------|
| Memory | 300-600MB | Varies by model size |
| CPU (idle) | <5% | Standby mode |
| CPU (transcribing) | 10-30% | Intel i5/i7 equivalent |
| Disk (executable) | 250-300MB | With base model bundled |
| Disk (models) | 40MB-1.55GB | Depends on selected model |

### Accuracy Metrics

| Metric | Value | Conditions |
|--------|-------|------------|
| Wake word detection | >95% | Quiet environment |
| Command recognition | ~90% | Trained commands |
| False positive rate | <2% | With cooldown |
| Disambiguation success | 85% | Ambiguous commands |

---

## Best Practices

### For End Users

1. **Environment Setup**
   - Use in quiet environment for best accuracy
   - Position microphone 6-12 inches from mouth
   - Adjust input volume to 70-80% in Windows settings

2. **Command Design**
   - Keep commands 2-4 words maximum
   - Use distinct, phonetically different phrases
   - Avoid commands that sound similar

3. **Training Workflow**
   - Train new commands 3-5 times
   - Use consistent pronunciation
   - Train in actual usage environment

4. **Maintenance**
   - Regularly review and delete unused commands
   - Monitor usage statistics to identify issues
   - Update weights for frequently-used commands

### For Developers

1. **Code Organization**
   - Each component is self-contained (audio, model, command, TTS)
   - Use dependency injection for testing
   - Follow thread-safe patterns with RLock

2. **Error Handling**
   - All external operations wrapped in try/except
   - Graceful degradation (e.g., disable VAD if unavailable)
   - Comprehensive logging to `stt_debug.log`

3. **Performance Optimization**
   - Minimize lock contention with fine-grained locking
   - Use asynchronous patterns for I/O operations
   - Cache frequently-accessed data

4. **Testing**
   - Test in both development and packaged modes
   - Verify COM initialization in frozen builds
   - Check resource cleanup with `verify_build.py`

---

## Contributing

We welcome contributions! Areas for enhancement:

- üåç Multi-language support (extend beyond English)
- üéØ Custom model fine-tuning on domain vocabulary
- üì± Cross-platform support (Linux, macOS)
- üîä Advanced audio preprocessing (noise cancellation)
- üìä Analytics dashboard for command usage
- üîê Voice biometrics for user authentication

Please submit issues and pull requests via GitHub.

---

## Documentation

- **BUILD_NOTES.md** - Comprehensive build system documentation
- **ÊûÑÂª∫‰øÆÂ§çËØ¥Êòé.md** - Chinese build fix guide
- **verify_build.py** - Automated build verification script
- **stt_debug.log** - Runtime debug log (created next to EXE)

---

## License

This project is provided for educational and research purposes. See LICENSE for full terms.

---

## Acknowledgments

### Third-Party Libraries

- **OpenAI Whisper** - State-of-the-art speech recognition
- **faster-whisper** - Optimized Whisper implementation
- **CTranslate2** - High-performance inference engine
- **ONNX Runtime** - VAD model execution
- **PyAudio** - Cross-platform audio I/O
- **pywin32** - Windows COM/SAPI integration
- **PyInstaller** - Application packaging

### Contributors

- **Project Maintainer:** YounGuru03
- **Repository:** [voice-control-for-a-robot-system](https://github.com/YounGuru03/voice-control-for-a-robot-system)
- **Branch:** windows_app_python

---

## Support

For issues, questions, or feature requests:
1. Check `stt_debug.log` for error details
2. Review troubleshooting section above
3. Consult BUILD_NOTES.md for build issues
4. Open GitHub issue with logs and reproduction steps

**System Status Check:**
```powershell
# View system health in GUI
# Navigate to System tab ‚Üí Click "Health Check"
```
