# ============================================================================
# optimized_audio_processor.py
# ============================================================================

import warnings
warnings.filterwarnings("ignore")

import os
import sys
import re
import time
import threading
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import numpy as np
import pyaudio
from typing import Optional, List, Dict, Any

# å¯¼å…¥ä¼˜åŒ–æ¨¡å—
from command_hotword_manager import CommandHotwordManager
from optimized_tts_manager import OptimizedTTSManager
from local_model_manager import LocalModelManager

# Whisperåç«¯æ£€æµ‹
BACKEND = None
try:
    from faster_whisper import WhisperModel
    BACKEND = "faster-whisper"
except ImportError:
    try:
        import whisper
        BACKEND = "openai-whisper"
    except ImportError:
        BACKEND = "none"
        print("âŒ WARNING: No Whisper backend available")

class OptimizedAudioProcessor:
    """ä¼˜åŒ–çš„éŸ³é¢‘å¤„ç†å™¨ - ä¿®å¤æ—¶é—´é—´éš”å’ŒTTSé—®é¢˜"""
    
    # çŠ¶æ€å®šä¹‰
    WAKE_STATE_INACTIVE = 0
    WAKE_STATE_ACTIVE = 1
    
    def __init__(self, model_size="base", language="en", device="cpu"):
        """åˆå§‹åŒ–éŸ³é¢‘å¤„ç†å™¨"""
        
        # åŸºç¡€é…ç½®
        self.language = language
        self.wake_state = self.WAKE_STATE_INACTIVE
        self.model_size = model_size
        self.device = device
        self.model = None
        
        # çŠ¶æ€ç®¡ç†
        self._lock = threading.Lock()
        self._processing = False
        self._last_command_time = 0
        self._command_cooldown = 3.0  # å¢åŠ åˆ°3ç§’å†·å´æ—¶é—´ï¼Œé˜²æ­¢è¯†åˆ«è¿‡å¿«
        
        # åˆå§‹åŒ–ç®¡ç†å™¨
        print("ğŸ”„ Initializing optimized processors...")
        
        # å‘½ä»¤çƒ­è¯ç®¡ç†å™¨
        self.cmd_hotword_mgr = CommandHotwordManager()
        
        # TTSç®¡ç†å™¨
        self.tts_mgr = OptimizedTTSManager()
        
        # æœ¬åœ°æ¨¡å‹ç®¡ç†å™¨
        self.model_mgr = LocalModelManager()
        
        # åˆå§‹åŒ–Whisperæ¨¡å‹
        self._initialize_whisper_model()
        
        print(f"âœ… OptimizedAudioProcessor initialized")
        print(f"   Model: {model_size}, Backend: {BACKEND}")
    
    def _initialize_whisper_model(self):
        """åˆå§‹åŒ–Whisperæ¨¡å‹"""
        try:
            if BACKEND == "faster-whisper":
                # ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç®¡ç†å™¨åŠ è½½æ¨¡å‹
                print(f"ğŸ”„ Loading local model: {self.model_size}")
                self.model = self.model_mgr.load_model(self.model_size)
                
                if self.model:
                    print("âœ… Using local faster-whisper model")
                else:
                    print("âŒ Failed to load local model")
                    
            elif BACKEND == "openai-whisper":
                import whisper
                self.model = whisper.load_model(self.model_size, device=self.device)
                print("âœ… Using openai-whisper model")
                
            else:
                print("âŒ No Whisper backend available")
                self.model = None
                
        except Exception as e:
            print(f"âŒ Model initialization error: {e}")
            self.model = None
    
    def set_wake_state(self, state):
        """è®¾ç½®å”¤é†’çŠ¶æ€ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        if state not in [self.WAKE_STATE_INACTIVE, self.WAKE_STATE_ACTIVE]:
            return False
        
        with self._lock:
            self.wake_state = state
            
        state_name = "ACTIVE" if state == 1 else "INACTIVE"
        print(f"ğŸ”„ Wake state: {state_name}")
        return True
    
    def get_wake_state(self):
        """è·å–å”¤é†’çŠ¶æ€"""
        with self._lock:
            return self.wake_state
    
    def is_active(self):
        """æ£€æŸ¥æ˜¯å¦æ´»è·ƒ"""
        return self.get_wake_state() == self.WAKE_STATE_ACTIVE
    
    def is_processing(self):
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†"""
        with self._lock:
            return self._processing
    
    def record_audio(self, duration=5, sample_rate=16000):
        """å½•åˆ¶éŸ³é¢‘ï¼ˆå‡å°‘ç»ˆç«¯è¾“å‡ºï¼‰"""
        chunk = 1024
        channels = 1
        
        try:
            p = pyaudio.PyAudio()
            
            # æŸ¥æ‰¾é»˜è®¤è¾“å…¥è®¾å¤‡ï¼ˆä¸è¾“å‡ºè®¾å¤‡ä¿¡æ¯ï¼‰
            default_device = p.get_default_input_device_info()
            # print(f"ğŸ¤ Using microphone: {default_device['name']}")  # ç§»é™¤ç»ˆç«¯è¾“å‡º
            
            stream = p.open(
                format=pyaudio.paInt16,
                channels=channels,
                rate=sample_rate,
                input=True,
                frames_per_buffer=chunk,
                input_device_index=default_device['index']
            )
            
            frames = []
            frames_to_read = int(sample_rate / chunk * duration)
            
            for i in range(frames_to_read):
                try:
                    data = stream.read(chunk, exception_on_overflow=False)
                    frames.append(data)
                except Exception as e:
                    # print(f"âš ï¸ Audio read warning: {e}")  # å‡å°‘è¾“å‡º
                    continue
            
            stream.stop_stream()
            stream.close()
            p.terminate()
            
            if not frames:
                print("âŒ No audio data recorded")
                return None
            
            audio_data = np.frombuffer(b''.join(frames), dtype=np.int16)
            audio_data = audio_data.astype(np.float32) / 32768.0
            
            # æ£€æŸ¥éŸ³é¢‘è´¨é‡ï¼ˆç®€åŒ–è¾“å‡ºï¼‰
            rms = np.sqrt(np.mean(audio_data**2))
            if rms < 0.001:  # å¤ªå®‰é™
                print("âš ï¸ Audio too quiet")
            
            # print(f"âœ… Recorded {duration}s audio, RMS: {rms:.4f}")  # å‡å°‘è¾“å‡º
            return audio_data
            
        except Exception as e:
            print(f"âŒ Recording error: {e}")
            return None
    
    def detect_wake_word(self, audio_data, wake_word="susie"):
        """æ£€æµ‹å”¤é†’è¯ï¼ˆå¢å¼ºå¤„ç†ï¼‰"""
        if audio_data is None or self.model is None:
            return False
        
        with self._lock:
            if self._processing:
                print("âš ï¸ Already processing, skipping wake word detection")
                return False
            self._processing = True
        
        try:
            # è·å–çƒ­è¯æå‡
            boost_phrases = [wake_word] + self.cmd_hotword_mgr.get_boost_phrases(5)
            
            # print(f"ğŸ” Detecting wake word '{wake_word}'...")  # å‡å°‘è¾“å‡º
            
            # è½¬å†™éŸ³é¢‘
            if BACKEND == "faster-whisper":
                initial_prompt = ", ".join(boost_phrases)
                segments, _ = self.model.transcribe(
                    audio_data,
                    language=self.language,
                    beam_size=1,
                    vad_filter=True,
                    initial_prompt=initial_prompt
                )
                text = " ".join([seg.text for seg in segments])
                
            elif BACKEND == "openai-whisper":
                initial_prompt = ", ".join(boost_phrases)
                result = self.model.transcribe(
                    audio_data, 
                    language=self.language, 
                    fp16=False,
                    initial_prompt=initial_prompt
                )
                text = result["text"]
            else:
                return False
            
            text = text.strip().lower()
            detected = wake_word.lower() in text
            
            # print(f"ğŸ” Wake word detection result: '{text}' -> {detected}")  # å‡å°‘è¾“å‡º
            
            if detected:
                print(f"âœ… Wake word '{wake_word}' detected")
                # TTSæ’­æŠ¥å”¤é†’
                self.tts_mgr.speak_status("please speak")
            
            return detected
            
        except Exception as e:
            print(f"âŒ Wake word detection error: {e}")
            return False
        finally:
            with self._lock:
                self._processing = False
    
    def transcribe(self, audio_data):
        """è½¬å†™éŸ³é¢‘ï¼ˆå¢å¼ºçŠ¶æ€æ£€æŸ¥å’Œé”™è¯¯å¤„ç†ï¼‰"""
        # çŠ¶æ€æ£€æŸ¥
        current_state = self.get_wake_state()
        if current_state != self.WAKE_STATE_ACTIVE:
            print(f"âŒ Not in active state (current: {current_state}), skipping transcription")
            return None
        
        if audio_data is None or self.model is None:
            print("âŒ No audio data or model not available")
            return None
        
        with self._lock:
            if self._processing:
                print("âš ï¸ Already processing, skipping transcription")
                return None
            self._processing = True
        
        try:
            # è·å–çƒ­è¯æå‡çŸ­è¯­
            boost_phrases = self.cmd_hotword_mgr.get_boost_phrases(15)
            initial_prompt = ", ".join(boost_phrases) if boost_phrases else None
            
            print("ğŸ”„ Transcribing audio...")
            
            # è½¬å†™éŸ³é¢‘
            if BACKEND == "faster-whisper":
                segments, _ = self.model.transcribe(
                    audio_data,
                    language=self.language,
                    beam_size=3,  # å‡å°‘beam_sizeæé«˜é€Ÿåº¦
                    vad_filter=True,
                    initial_prompt=initial_prompt
                )
                text = " ".join([seg.text for seg in segments])
                
            elif BACKEND == "openai-whisper":
                result = self.model.transcribe(
                    audio_data,
                    language=self.language,
                    fp16=False,
                    initial_prompt=initial_prompt
                )
                text = result["text"]
            else:
                return None
            
            text = text.strip()
            
            # æ•°å­—æ ¼å¼åŒ–å¤„ç†
            text = self._format_numbers(text)
            
            print(f"âœ… Transcription result: '{text}'")
            return text if text else None
            
        except Exception as e:
            print(f"âŒ Transcription error: {e}")
            return None
        finally:
            with self._lock:
                self._processing = False
    
    def _format_numbers(self, text: str) -> str:
        """æ ¼å¼åŒ–æ•°å­—è¾“å‡º"""
        if not text:
            return text
        
        # è‹±æ–‡æ•°å­—è¯æ±‡åˆ°é˜¿æ‹‰ä¼¯æ•°å­—çš„æ˜ å°„
        number_words = {
            'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4',
            'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9',
            'ten': '10', 'eleven': '11', 'twelve': '12', 'thirteen': '13',
            'fourteen': '14', 'fifteen': '15', 'sixteen': '16', 'seventeen': '17',
            'eighteen': '18', 'nineteen': '19', 'twenty': '20', 'thirty': '30',
            'forty': '40', 'fifty': '50', 'sixty': '60', 'seventy': '70',
            'eighty': '80', 'ninety': '90', 'hundred': '100', 'thousand': '1000'
        }
        
        # æ›¿æ¢è‹±æ–‡æ•°å­—ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—
        words = text.split()
        for i, word in enumerate(words):
            word_lower = word.lower().strip('.,!?')
            if word_lower in number_words:
                words[i] = word.replace(word_lower, number_words[word_lower])
        
        return ' '.join(words)
    
    def match_command(self, text, commands):
        """åŒ¹é…å‘½ä»¤ï¼ˆå¢å¼ºå†·å´æ—¶é—´å¤„ç†ï¼‰"""
        if not text or not commands:
            return None
        
        # æ£€æŸ¥å†·å´æ—¶é—´
        current_time = time.time()
        if current_time - self._last_command_time < self._command_cooldown:
            print(f"âš ï¸ Command cooldown active ({self._command_cooldown}s)")
            return None
        
        text_lower = text.lower().strip()
        matched_command = None
        
        # ç²¾ç¡®åŒ¹é…å’ŒåŒ…å«åŒ¹é…
        for cmd in commands:
            cmd_lower = cmd.lower().strip()
            if cmd_lower == text_lower or cmd_lower in text_lower:
                matched_command = cmd
                break
        
        # è®°å½•ä½¿ç”¨æƒ…å†µ
        if matched_command:
            self.cmd_hotword_mgr.record_usage(matched_command, success=True)
            self._last_command_time = current_time
            
            # TTSæ’­æŠ¥å‘½ä»¤
            self.tts_mgr.speak_command(matched_command)
            
            print(f"âœ… Command matched: '{text}' -> '{matched_command}'")
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†åŒ¹é…
            for word in text_lower.split():
                if word in [cmd.lower() for cmd in commands]:
                    self.cmd_hotword_mgr.record_usage(word, success=False)
            
            # TTSæ’­æŠ¥æœªåŒ¹é…
            self.tts_mgr.speak_status("not match")
            
            print(f"âŒ No command match for: '{text}'")
        
        return matched_command
    
    def reset_wake_state(self):
        """é‡ç½®å”¤é†’çŠ¶æ€"""
        with self._lock:
            self.wake_state = self.WAKE_STATE_INACTIVE
            self._processing = False
        
        print("ğŸ”„ Wake state reset to INACTIVE")
        # TTSæ’­æŠ¥çŠ¶æ€é‡ç½®
        self.tts_mgr.speak_status("stand by")
    
    def add_command(self, text: str) -> bool:
        """æ·»åŠ å‘½ä»¤"""
        return self.cmd_hotword_mgr.add_command(text)
    
    def remove_command(self, text: str) -> bool:
        """åˆ é™¤å‘½ä»¤"""
        return self.cmd_hotword_mgr.remove_command(text)
    
    def get_all_commands(self) -> List[str]:
        """è·å–æ‰€æœ‰å‘½ä»¤"""
        return self.cmd_hotword_mgr.get_all_commands()
    
    def train_command(self, text: str) -> float:
        """è®­ç»ƒå‘½ä»¤"""
        return self.cmd_hotword_mgr.train_command(text)
    
    def get_training_count(self, text: str) -> int:
        """è·å–è®­ç»ƒæ¬¡æ•°"""
        return self.cmd_hotword_mgr.get_training_count(text)
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        with self._lock:
            current_wake_state = self.wake_state
            current_processing = self._processing
        
        status = {
            "wake_state": current_wake_state,
            "processing": current_processing,
            "model_size": self.model_size,
            "backend": BACKEND,
            "model_loaded": self.model is not None,
            "features": {
                "tts_enabled": True,
                "hotwords_enabled": True,
                "embedded_models": True
            }
        }
        
        # å‘½ä»¤ç»Ÿè®¡
        cmd_stats = self.cmd_hotword_mgr.get_statistics()
        status["commands"] = {
            "total": cmd_stats["total"],
            "most_used": cmd_stats["most_used"][:3]
        }
        
        # TTSçŠ¶æ€
        tts_info = self.tts_mgr.get_engine_info()
        status["tts"] = {
            "engine_type": tts_info["engine_type"],
            "enabled": tts_info["enabled"],
            "running": tts_info["running"],
            "speaking": tts_info["speaking"]
        }
        
        # æ¨¡å‹çŠ¶æ€
        model_info = self.model_mgr.get_system_info()
        status["local_models"] = {
            "offline_mode": model_info["offline_mode"],
            "available": model_info["available_models"],
            "total_size": model_info["total_size"]
        }
        
        return status
    
    def shutdown(self):
        """å…³é—­å¤„ç†å™¨"""
        print("ğŸ”„ Shutting down audio processor...")
        
        # é‡ç½®çŠ¶æ€
        with self._lock:
            self.wake_state = self.WAKE_STATE_INACTIVE
            self._processing = False
        
        # åœæ­¢TTS
        if self.tts_mgr:
            self.tts_mgr.stop()
        
        print("âœ… Audio processor shutdown complete")